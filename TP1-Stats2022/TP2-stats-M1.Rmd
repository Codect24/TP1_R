---
title : Compte-rendu Statistiques -- TP2
subtitle: Analyse en composantes principales et apprentissage
author : Manon MARTIN et Tom LEFRERE
always_allow_html: true
output:
  pdf_document:
    number_sections: yes


---


\tableofcontents


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(rgl.useNULL = TRUE)
library(readr)
library(ggplot2)
library(rgl)
library(dplyr)
library(PerformanceAnalytics)
library(FactoMineR)
library(factoextra)
library(tidyr)
library(corrplot)
library(plotly)
library(class)


rgl::setupKnitr(autoprint = TRUE)

#Chargement des données
iris <- read_delim("TP1-Stats2022/iris.csv", ";", escape_double = FALSE)
sleep <- read.delim("TP1-Stats2022/sleep.csv", sep = ";", header = TRUE, dec = ".")
mnist <- read.csv("TP1-Stats2022/mnist.csv", sep = ";", header = TRUE)
```
```

# Exercices

## Les iris de Fischer

On considère le fichier `iris.csv` sur Celene répertoriant 150 individus fleurs d'iris. On donne la description suivante des colonnes:


|Colonne|Description|Value|
|---------------|-------------------|-----------------------|
|`sepal_length`|Longueur des sépales|Int|
|`sepal_width`|Largeur des sépales|Int|
|`petal_length`|Longueur des pétales|Int|
|`petal_width`|Largeur des pétales|Int|
|`species`|Espèce d'iris|\{Versicolor, Virginica, Setosa\}|

1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `iris`. Votre analyse^[Vous pourrez vous aider la fonction `chart.Correlation` de la librairie `PerformanceAnalytics`. ] devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées par espèce.

> > - Corrélation entre les variables.

```{r}
#Distribution des variables par espèce
ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Sepal.Width, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Petal.Length, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Petal.Width, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
```

```{r, webgl=TRUE}
    #Visualisation des données dans un plan 3D avec rgl
    # On attribue une couleur à chaque espèce
    iris$color <- ifelse(iris$Species == "setosa", "red", ifelse(iris$Species == "versicolor", "blue", "green"))
    # On affiche les données dans une fenetre
    plot3d(iris$Sepal.Length, iris$Sepal.Width, iris$Petal.Length, col = iris$color, type = "p", pch = 16, size = 3, xlab = "Sepal Length", ylab = "Sepal Width", zlab = "Petal Length", main = "Iris", ticktype = "detailed", box = FALSE)
```
```{r}
    #Analyse synthétique agrégée par espèce
    iris %>% group_by(Species) %>% summarise_all(funs(mean, sd))

```
```{r}
    #Corrélation entre les variables
    chart.Correlation(iris[,1:4], histogram=TRUE, pch=19, col=c("red", "blue", "green"))
```


> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ?
> Les variables Petal.Length et Petal.Width semblent pertinentes pour l'ACP.

```{r}
    #On ne garde que les variables pertinentes pour l'ACP soit les moins corrélées (les sepals)
    iris_pour_acp <- iris[,1:4]
```

2.  Calculer les valeurs propres de la matrice des données `iris`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse. 

```{r}
    #Calcul des valeurs propres
    acp <- PCA(iris_pour_acp, graph = FALSE)
    acp$eig
```

3. Analyse des variables

> (a) Dresser le cercle des corrélations de l'ACP. Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus. 

```{r}
    #Cercle des corrélations avec un gradient de couleur pour la contribution des variables
    fviz_pca_var(acp, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels.

```{r}
        #Contribution des variables aux axes factoriels avec un gradient de couleur et des couleur par espèce
        fviz_pca_biplot(acp, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

4. Analyse des individus

> (a) Présenter la projection des indivus dans le plan factoriel. Vous colorerez dans un premier temps les points en fonction de l'espèce d'iris. 

```{r}
        #Projection des individus dans le plan factoriel
        fviz_pca_ind(acp, repel = TRUE, col.ind = iris$Species)
```
> (b) Colorer les individus en fonction de leur contribution aux axes factoriels. Que remarquez-vous ? Pouvez l'expliquer ? 

```{r}
        #Coloration des individus en fonction de leur contribution aux axes factoriels
        fviz_pca_ind(acp, repel = TRUE, col.ind = "contrib")
```

> (c) Commenter la qualité de représentation des individus. 

5. Apprentissage statistique

> L'option `addEllipses=TRUE` de la fonction `fviz_pca_ind` permet de dessiner l'ellipse de confiance (covariance ellipse error) à 95%. 

> (a) Sous quelle condition la définition d'ellipses de confiance est-elle valable ? Est-ce le cas selon vous-ici ? Pourquoi ?
```{r}
        #On affiche les ellipses de confiance
        fviz_pca_ind(acp, repel = TRUE, col.ind = iris$Species, addEllipses = TRUE)
```

> (b) Proposer un algorithme permettant de classifier automatiquement une nouvelle iris inconnue et ainsi déterminer son espèce. Vous évoquerez les limites de votre approche et possibilités pour pallier à ces effets. 

```{r}
        # TODO
```


5. Reprendre l'analyse du jeu de données `iris` mais en effectuant ici une ACP **non réduite**. On appliquera pour ça l'option `scale = FALSE` lors de l'exécution de la fonction `PCA`. 

> Que remarquez vous ? Quelle méthode semble finalement donner les meilleurs résultats ici ? Expliquer ces résultats.

```{r}
        #ACP non réduite
        acp_non_reduite <- PCA(iris_pour_acp, graph = FALSE, scale = FALSE)
        acp_non_reduite$eig
```

```{r}
        #Cercle des corrélations avec un gradient de couleur pour la contribution des variables
        fviz_pca_var(acp_non_reduite, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

```{r}
        #Contribution des variables aux axes factoriels avec un gradient de couleur et des couleur par espèce
        fviz_pca_biplot(acp_non_reduite, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

```{r}
        #Projection des individus dans le plan factoriel
        fviz_pca_ind(acp_non_reduite, repel = TRUE, col.ind = iris$Species)
```

```{r}
        #Coloration des individus en fonction de leur contribution aux axes factoriels
        fviz_pca_ind(acp_non_reduite, repel = TRUE, col.ind = "contrib")
```


## Sommeil des mammifères

On considère le fichier `sleep.csv` sur Celene répertoriant les données de 70 espèces de mammifères concernant leur sommeil et quelques autres caractéristiques. On donne la description suivante des colonnes :

| Colonne            | Description                                                                      | Value  |
|--------------------|----------------------------------------------------------------------------------|--------|
| `name`             | Nom français vernaculaire de l'animal                                            | String |
| `genus`            | Genre, subdivion de la classification biologique                                 | String |
| `vore`             | Régime alimentaire de l'animal                                                   | String |
| `order`            | Ordre, subdivion de la classification biologique                                 | String |
| `sleep_total`      | Durée (en h) de sommeil sur une journée                                          | Double |
| `sleep_rem`        | Durée (en h) de sommeil paradoxal                                                | Double |
| `awake`            | Durée (en h) où l'animal est éveillé                                             | Double |
| `brain_wt`         | Masse (en kg) moyenne du cerveau de l'animal                                     | Double |
| `body_wt`          | Masse (en kg) totale moyenne de l'animal                                         | Double |
| `brain_body_ratio` | Ratio masse cerveau, masse totale $\frac{\mathtt{brain\_wt}}{\mathtt{body\_wt}}$ | Double |
| `gest_day`         | Période de gestation moyenne de l'animal                                         | Int    |



1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `sleep`. Votre analyse devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées selon différentes variables qualitatives.

> > - Corrélation entre les variables.

```{r}
        #Distribution des variables
        sleep %>%
                select(-name, -genus, -vore, -order) %>%
                gather(key = "variable", value = "valeur") %>%
                ggplot(aes(x = valeur)) +
                geom_histogram(bins = 30) +
                facet_wrap(~variable, scales = "free")

```
```{r}
        #Corrélation entre les variables avec corrplot (pour changer)
        sleep %>%
                select(-name, -genus, -vore, -order) %>%
                cor() %>%
                round(2) %>%
                corrplot()
```

```{r}
 #Corrélation entre les variables avec plotly (plus interactif)
        cor_mat <- cor(sleep[, -c(1, 2, 3, 4)])
        plot_ly(z = cor_mat, x = colnames(cor_mat), y = colnames(cor_mat), type = "heatmap", colors = "Blues")
```

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? Quelles variables explicatives proposez-vous ?

```{r}
        #On ne garde que les variables pertinentes pour l'ACP
        sleep_pour_acp <- sleep %>%
                select(sleep_total, sleep_rem, awake, brain_wt, body_wt, brain_body_ratio, gest_day)

        #On vérifie qu'il n'y a pas de valeurs manquantes
        sum(is.na(sleep_pour_acp))

        #On vérifie qu'il n'y a pas de valeurs négatives
        sum(sleep_pour_acp < 0)

        #On vérifie qu'il n'y a pas de valeurs aberrantes
        sleep_pour_acp %>%
                select(-gest_day) %>%
                gather(key = "variable", value = "valeur") %>%
                ggplot(aes(x = valeur)) +
                geom_histogram(bins = 30) +
                facet_wrap(~variable, scales = "free")


```

2. On propose de compléter les données manquantes de la colonne `sleep_rem` en utilisant une technique de regression  par _la méthode des moindres carrés_. Quelle valeur est estimée pour l'individu _Lamantin_ ? Compléter les valeurs manquantes.

```{r}


```

3. Calculer les valeurs propres de la matrice des données `sleep`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse. 

4. Analyse des variables

> (a) Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus. 

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels. 

5. Analyse des individus

> (a) Présenter la projection des indivus dans l'espace factoriel retenu. Vous colorerez dans un premier temps les points en fonction de la variable explicative retenue. 

> >  Pour une projection 3D, on utilisera la commande `plot_ly(df, x = ~Dim.1, y = ~Dim.2, z = ~Dim.3)` de la librairie `plotly` où `df` est votre dataframe des coordonnées des individus et `Dim.k`, la colonne des coordonnées sur l'axe $k$. 

> (b) Colorer les individus en fonction de leur qualité de réprésentation aux axes factoriels puis en fonction de la contribution. Commentez ces résultats. 
 

## Classiffication de caractères manuscrits

On considère le fichier `mnist.csv` sur Celene. Ces données proviennent de la base MNIST^[http://yann.lecun.com/exdb/mnist/] sur laquelle des milliers de chercheurs ont travaillé. Elle est constituée initialement de 70.000 chiffres manuscrits au format 28 pixels par 28 pixels où chaque pixel est représenté par un niveau de gris allant de 0 à 255. Un chiffre manuscrit est vu comme un vecteur de $\{0, ..., 255\}^{28\times28}$.


Pour limiter le temps de calcul et la mémoire nécessaire, nous ne considérons que les 20.000 premiers chiffres manuscrits de la base originale. On donne la description des colonnes suivantes:

- chaque ligne correspond à un chiffre manuscrit.

- la première colonne contient la _classe_ (ou label) du caractère, c'est-à-dire le chiffre qu'il représente.

- les colonnes suivantes, contiennent les valeurs des $28\times 28=784$ pixels de l'image en commençant par le coin supérieur gauche et parcourant l’image ligne par ligne.

On donne la fonction de visualisation suivante: 

```{r}
img <- function(data, row_index){

    r <- as.numeric(data[row_index, 2:785])
    im <- matrix(nrow = 28, ncol = 28)
    j <- 1
    for(i in 28:1){
        im[,i] <- r[j:(j+27)]
        j <- j+28
    }  
    png(file = "out.png", width = 210, height = 300)

    image(x = 1:28, 
          y = 1:28, 
          z = im, 
          col=gray((0:255)/255), 
          main = paste("Number:", data[row_index, 1]))
    dev.off()
}
```

L'appel `img(mnist, i)` retourne la figure correspondant au caractère manuscrit ligne $i$. 

1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `mnist`. Votre analyse devra contenir notamment:

> >- Nombre de caractères de chaque classe.

```{r}
# Definition du jeu de données mnist : label, pixel0, pixel1, ..., pixel783
        #Nombre de caractères de chaque classe dans un plotly
        mnist %>%
                group_by(label) %>%
                summarise(n = n()) %>%
                plot_ly(x = ~label, y = ~n, type = "bar", text = ~n, textposition = "auto")
```

> >- Des premiers indicateurs sur la proportion de gris par pixel, puis agrégé par classe de caractère.

```{r}
        #Proportion de gris par pixel
        #Transformation de label comme valeur discrète
        mnist$label <- as.factor(mnist$label)
        #On calcule la moyenne de chaque pixel par label et on affiche le résultat avec des bar groupés par label avec des couleurs avec plotly
        mnist %>%
                group_by(label) %>%
                summarise_all(mean) %>%
                gather(key = "pixel", value = "proportion_gris", -label) %>%
                mutate(pixel = as.numeric(gsub("pixel", "", pixel))) %>%
                plot_ly(x = ~pixel, y = ~proportion_gris, color = ~label, type = "bar")
```

```{r}
        #On refait la meme chose mais avec ggplot
        mnist %>%
                group_by(label) %>%
                summarise_all(mean) %>%
                gather(key = "pixel", value = "proportion_gris", -label) %>%
                ggplot(aes(x = pixel, y = proportion_gris, group = label, color = label)) +
                geom_line() +
                theme_bw() +
                theme(legend.position = "bottom") +
                labs(x = "Pixel", y = "Proportion de gris", title = "Proportion de gris par pixel")
```

> (b) Sur la base de ces analyses, certaines zones de l'image vous semblent t-elles plus pertinentes pour l'analyse ? Lesquelles ? Pourquoi ?

> > On remarque que les pixels centraux sont plus importants que les autres. On peut donc se concentrer sur ces pixels pour l'analyse.

2. Classification par l'algorithme des $k$ plus proches voisins (kNN). 

> L'algorithme des $k$ proches voisins ($k$-Nearest Neightbors) est une méthode de prédiction qui, pour une base de données d'apprentissage, cherche à déterminer la classe d'une donnée inconnue. 

> L'idée générale de cet algorithme est très simple. Pour une nouvelle donnée d'entrée $x$, on évalue sa distance à toutes les autres données connues de notre base d'apprentissage $\mathbf{X}$. 

> On rappelle que la distance euclidienne entre deux éléments $x,y\in \mathbb{R}^p$ est définie telle que:

$$\left\Vert x-y\right\Vert = \sqrt{\sum_{i=1}^p (x_i-y_i)^2}$$

> On retient ensuite uniquement les $k$ voisins $\mathbf{X_i}$ les plus proches de $x$. On regarde alors les classes $\mathbf{Y_i}$ de ces données $\mathbf{X_i}$, puis on prédit la classe la plus présente. Par défaut on utilisera $k=1$.

> (a) En assumant que $\mathbf{X}$ est doté de $n$ individus définis dans un espace de dimension $p$. Quelle est la complexité de l'algorithme des $k$-Nearest Neightbors pour $k = 1$. 

> (b) Diviser le jeu de données `mnist` en deux ensembles : 

> > - Un ensemble d'apprentissage (train set) qui contiendra 80% du jeu initial.

> > - Un ensemble test (test set) qui contiendra le reste des données.

```{r}
# On crée un jeu de données train qui contient 80% des données de mnist et un jeu de données test qui contient les 20% restants
        train <- mnist %>%
                group_by(label) %>%
                sample_frac(0.8)
        test <- mnist %>%
                anti_join(train)
```

> On veillera à conserver les labels des deux ensembles dans un vecteur à part. 

> (c) La commande `knn` du package `class` permet de réaliser une classification à l'aide de l'algorithme des $k$-Nearest Neightbors:

> > Appliquer l'algorithme kNN (avec $k=1$) sur votre ensemble d'apprentissage et de test. On veillera à sauvegarder le résultat de la fonction dans une variable `prediction`:

> > > `prediction <- knn(...)`
```{r, eval = FALSE}
# On applique l'algorithme knn avec k=1 sur l'ensemble d'apprentissage et de test
        prediction <- knn(train[, -1], test[, -1], cl = train$label, k = 1)
```

> > Donner le temps d'exécution de l'algorithme.
> > > Le temps d'exécution de l'algorithme est de 8 minutes.

> (d) La commande `table(prediction, Y_test_label)` permet de dresser la _matrice de confusion_ $C$ de la classification effectuée. Le nombre $c_{ij}$ représente le nombre d'éléments de la classe $i$ classifiés en tant que $j$. 

> > Quel est le pourcentage de caractères manuscrits de l’ensemble de test qui ont été mal classés ? Cet algorithme vous semble t-il efficace ? Quel critique peut-on lui faire ?
```{r}
# On calcule le pourcentage de caractères manuscrits de l'ensemble de test qui ont été mal classés avec ggplot
        table(prediction, test$label)

```
> (e) Pour chaque classe, identifier un exemple de caractère mal classé par l'algorithme. Vous illustrerez ces caractères à l'aide de la fonction `img` donnée plus haut et ferez figurer la classe prédite et réelle des caractères. 
```{r}
# On crée un jeu de données qui contient les caractères mal classés
        mal_classe <- test %>%
                mutate(prediction = prediction) %>%
                filter(label != prediction)
# Pour chaque mal classé on appel la fonction img(data, i) qui permet d'afficher le caractère i et copie out.png dans le dossier erreur avec pour nom le label et la prediction
        for (i in 1:nrow(mal_classe)) {
                img(mal_classe, i)
                file.rename("out.png", paste0("erreur/", mal_classe$label[i], "_", mal_classe$prediction[i], ".png"))
        }
# On fait un rapport avec un tableau sur le label et la prediction
#         knitr::kable(mal_classe[, c("label", "prediction")])
```

3. Prétraitement-compression des données par ACP

> (a) Effectuer une ACP du jeu `mnist` et analyser la série des valeurs propres. Combien de composantes doivent être conservées pour avoir plus de 95% de l’inertie.
```{r}
# On effectue une ACP du jeu mnist avec la fonction acp
        mnist_acp <- PCA(mnist[, -1], graph = FALSE)
```

```{r}
# On affiche la série des valeurs propres
#         mnist_acp$eig
# On affiche la screeplot
fviz_screeplot(mnist_acp, ncp = 20)

# On affiche la courbe de l'inertie cumulée
fviz_eig(mnist_acp, addlabels = TRUE, ylim = c(0, 100))

# On affiche le pca ind avec les couleurs indiquant leurs importance du cos2
fviz_pca_ind(mnist_acp, col.var = "cos2", repel = TRUE, legend.title = "Cos2")
```

```{r}
```

> > On conserve 95% de l'inertie avec 303 composantes.
>
> (b) Appliquer à nouveau l'algorithme kNN mais ici vous utiliserez comme jeu initial la projection via ACP réalisée à la question précédente. Que constatez-vous ? 
```{r}
# On applique l'algorithme knn avec k=1 sur l'ensemble d'apprentissage et de test avec la projection via ACP
        prediction_acp <- knn(mnist_acp$ind$coord[, 1:303], mnist_acp$ind$coord[, 1:303], cl = train$label, k = 1)


```
> (c) Dresser la nouvelle matrice de confusion à l'issu de la classification précédente. Comparer ces résultats avec la matrice de la question 2. (d). Que peut-on dire ?
```{r}
# On calcule le pourcentage de caractères manuscrits de l'ensemble de test qui ont été mal classés
        table(prediction, test$label) %>%
                as.matrix() %>%
                prop.table(1) %>%
                as.data.frame() %>%
                mutate(label = rownames(.)) %>%
                select(label, prediction) %>%
                filter(label != prediction) %>%
                summarise(pourcentage = sum(prediction))
```
