---
title : Compte-rendu Statistiques -- TP2
subtitle: Analyse en composantes principales et apprentissage
author : Manon MARTIN et Tom LEFRERE
always_allow_html: true
output:
  pdf_document:
    number_sections: yes


---


\tableofcontents


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(rgl.useNULL = TRUE)
library(readr)
library(ggplot2)
library(rgl)
library(dplyr)
library(PerformanceAnalytics)
library(FactoMineR)
library(factoextra)
library(tidyr)
library(corrplot)
library(plotly)
library(class)


rgl::setupKnitr(autoprint = TRUE)

#Chargement des données
iris <- read_delim("TP1-Stats2022/iris.csv", ";", escape_double = FALSE)
sleep <- read.delim("TP1-Stats2022/sleep.csv", sep = ";", header = TRUE, dec = ".")
mnist <- read.csv("TP1-Stats2022/mnist.csv", sep = ";", header = TRUE)
```


# Exercices

## Les iris de Fischer

On considère le fichier `iris.csv` sur Celene répertoriant 150 individus fleurs d'iris. On donne la description suivante des colonnes:


|Colonne|Description|Value|
|---------------|-------------------|-----------------------|
|`sepal_length`|Longueur des sépales|Int|
|`sepal_width`|Largeur des sépales|Int|
|`petal_length`|Longueur des pétales|Int|
|`petal_width`|Largeur des pétales|Int|
|`species`|Espèce d'iris|\{Versicolor, Virginica, Setosa\}|

1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `iris`. Votre analyse^[Vous pourrez vous aider la fonction `chart.Correlation` de la librairie `PerformanceAnalytics`. ] devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées par espèce.

> > - Corrélation entre les variables.

```{r}
#Distribution des variables par espèce
ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Sepal.Width, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Petal.Length, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
ggplot(iris, aes(x = Petal.Width, fill = Species)) + geom_histogram(bins = 20, alpha = 0.5, position = "identity") + facet_wrap(~Species, scales = "free")
```

```{r, webgl=TRUE}
    #Visualisation des données dans un plan 3D avec la librairie rgl
    # On attribue une couleur à chaque espèce
    iris$color <- ifelse(iris$Species == "setosa", "red", ifelse(iris$Species == "versicolor", "blue", "green"))
    # On affiche les données dans une fenetre
    plot3d(iris$Sepal.Length, iris$Sepal.Width, iris$Petal.Length, col = iris$color, type = "p", pch = 16, size = 3, xlab = "Sepal Length", ylab = "Sepal Width", zlab = "Petal Length", main = "Iris", ticktype = "detailed", box = FALSE)
```
```{r}
    #Analyse synthétique agrégée par espèce
    iris %>% group_by(Species) %>% summarise_all(funs(mean, sd))

```
```{r}
    #Corrélation entre les variables
    chart.Correlation(iris[,1:4], histogram=TRUE, pch=19, col=c("red", "blue", "green"))
```


> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ?
> Les variables Petal.Length et Petal.Width semblent pertinentes pour l'ACP.

```{r}
    #On ne garde que les variables pertinentes pour l'ACP soit les moins corrélées (les sepals)
    iris_pour_acp <- iris[,1:4]
```

2.  Calculer les valeurs propres de la matrice des données `iris`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse. 

```{r}
    #Calcul des valeurs propres
    acp <- PCA(iris_pour_acp, graph = FALSE)
    acp$eig
```

3. Analyse des variables

> (a) Dresser le cercle des corrélations de l'ACP. Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus. 

```{r}
    #Cercle des corrélations avec un gradient de couleur pour la contribution des variables
    fviz_pca_var(acp, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels.

```{r}
        #Contribution des variables aux axes factoriels avec un gradient de couleur et des couleur par espèce
        fviz_pca_biplot(acp, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

4. Analyse des individus

> (a) Présenter la projection des individus dans le plan factoriel. Vous colorerez dans un premier temps les points en fonction de l'espèce d'iris.

```{r}
        #Projection des individus dans le plan factoriel
        fviz_pca_ind(acp, repel = TRUE, col.ind = iris$Species)
```
> (b) Colorer les individus en fonction de leur contribution aux axes factoriels. Que remarquez-vous ? Pouvez l'expliquer ? 

```{r}
        #Coloration des individus en fonction de leur contribution aux axes factoriels
        fviz_pca_ind(acp, repel = TRUE, col.ind = "contrib")
```
> > On peut voir que les individus qui contribuent le plus aux axes factoriels sont ceux qui sont les plus extrêmes. Cela peut s'expliquer par le fait que les individus qui contribuent le plus aux axes factoriels sont ceux qui sont les plus éloignés des autres individus.
> (c) Commenter la qualité de représentation des individus.
> > La qualité de représentation des individus est bonne. On peut voir que les individus sont bien répartis dans le plan factoriel. Cependant, on peut voir que les individus de la même espèce ne sont pas tous regroupés ensemble, notamment pour l'espèce versicolor et vigernica.
5. Apprentissage statistique

> L'option `addEllipses=TRUE` de la fonction `fviz_pca_ind` permet de dessiner l'ellipse de confiance (covariance ellipse error) à 95%. 

> (a) Sous quelle condition la définition d'ellipses de confiance est-elle valable ? Est-ce le cas selon vous-ici ? Pourquoi ?
> > La définition d'ellipses de confiance est valable lorsque les ellipses ne se chevauchent pas. Ici, les ellipses se chevauchent donc la définition n'est pas valable.
```{r}
        #On affiche les ellipses de confiance
        fviz_pca_ind(acp, repel = TRUE, col.ind = iris$Species, addEllipses = TRUE)
```

> (b) Proposer un algorithme permettant de classifier automatiquement une nouvelle iris inconnue et ainsi déterminer son espèce. Vous évoquerez les limites de votre approche et possibilités pour pallier à ces effets.
> > Un classification KNN semble être une bonne approche pour classifier automatiquement une nouvelle iris inconnue.
> > Cependant, il faudrait faire attention à la distance utilisée pour le calcul des voisins car si la distance utilisée est trop grande, on risque de classer une nouvelle iris inconnue dans la mauvaise espèce. Il faudrait donc faire attention à la distance utilisée pour le calcul des voisins. Il faudrait également faire attention à la valeur de K car si K est trop grand, on risque de classer une nouvelle iris inconnue dans la mauvaise espèce.
> > Teston avec un K = 3

```{r}
        # KNN avec k=3 pour classifier automatiquement une nouvelle iris inconnue
        # On crée un jeu de données de test qui contient 20% des données
        set.seed(123)
        iris_train <- iris[sample(1:nrow(iris), 0.8*nrow(iris)),]
        iris_test <- iris[-sample(1:nrow(iris), 0.8*nrow(iris)),]
        # On crée un jeu de données d'apprentissage qui contient les autres iris
        iris_app <- iris[-sample(1:nrow(iris), 0.8*nrow(iris)),]
        # On crée un modèle de classification KNN avec k=3
        modele_knn <- knn(train = iris_app[,1:4], test = iris_test[,1:4], cl = iris_app$Species, k = 3)
        # On affiche le modèle de classification KNN
        modele_knn
        # On affiche la matrice de confusion
        table(iris_test$Species, modele_knn)
        # On affiche le taux de bonne classification
        sum(diag(table(iris_test$Species, modele_knn)))/sum(table(iris_test$Species, modele_knn))
```

5. Reprendre l'analyse du jeu de données `iris` mais en effectuant ici une ACP **non réduite**. On appliquera pour ça l'option `scale = FALSE` lors de l'exécution de la fonction `PCA`. 

> Que remarquez vous ? Quelle méthode semble finalement donner les meilleurs résultats ici ? Expliquer ces résultats.

```{r}
        #ACP non réduite
        acp_non_reduite <- PCA(iris_pour_acp, graph = FALSE, scale = FALSE)
        acp_non_reduite$eig
```

```{r}
        #Cercle des corrélations avec un gradient de couleur pour la contribution des variables
        fviz_pca_var(acp_non_reduite, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

```{r}
        #Contribution des variables aux axes factoriels avec un gradient de couleur et des couleur par espèce
        fviz_pca_biplot(acp_non_reduite, repel = TRUE, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```

```{r}
        #Projection des individus dans le plan factoriel
        fviz_pca_ind(acp_non_reduite, repel = TRUE, col.ind = iris$Species)
```

```{r}
        #Coloration des individus en fonction de leur contribution aux axes factoriels
        fviz_pca_ind(acp_non_reduite, repel = TRUE, col.ind = "contrib")
```

```{r}
        #On affiche les ellipses de confiance
        fviz_pca_ind(acp_non_reduite, repel = TRUE, col.ind = iris$Species, addEllipses = TRUE)
```

## Sommeil des mammifères

On considère le fichier `sleep.csv` sur Celene répertoriant les données de 70 espèces de mammifères concernant leur sommeil et quelques autres caractéristiques. On donne la description suivante des colonnes :

| Colonne            | Description                                                                      | Value  |
|--------------------|----------------------------------------------------------------------------------|--------|
| `name`             | Nom français vernaculaire de l'animal                                            | String |
| `genus`            | Genre, subdivion de la classification biologique                                 | String |
| `vore`             | Régime alimentaire de l'animal                                                   | String |
| `order`            | Ordre, subdivion de la classification biologique                                 | String |
| `sleep_total`      | Durée (en h) de sommeil sur une journée                                          | Double |
| `sleep_rem`        | Durée (en h) de sommeil paradoxal                                                | Double |
| `awake`            | Durée (en h) où l'animal est éveillé                                             | Double |
| `brain_wt`         | Masse (en kg) moyenne du cerveau de l'animal                                     | Double |
| `body_wt`          | Masse (en kg) totale moyenne de l'animal                                         | Double |
| `brain_body_ratio` | Ratio masse cerveau, masse totale $\frac{\mathtt{brain\_wt}}{\mathtt{body\_wt}}$ | Double |
| `gest_day`         | Période de gestation moyenne de l'animal                                         | Int    |



1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `sleep`. Votre analyse devra contenir notamment:

> > - Distribution de chaque variable puis analyses synthétiques agrégées selon différentes variables qualitatives.

> > - Corrélation entre les variables.

```{r}
        #Distribution des variables
        sleep %>%
                select(-name, -genus, -vore, -order) %>%
                gather(key = "variable", value = "valeur") %>%
                ggplot(aes(x = valeur)) +
                geom_histogram(bins = 30) +
                facet_wrap(~variable, scales = "free")

```
```{r}
        #Corrélation entre les variables avec corrplot (pour changer)
        sleep %>%
                select(-name, -genus, -vore, -order) %>%
                cor() %>%
                round(2) %>%
                corrplot()
```

```{r}
 #Corrélation entre les variables avec plotly (plus interactif)
        cor_mat <- cor(sleep[, -c(1, 2, 3, 4)])
        plot_ly(z = cor_mat, x = colnames(cor_mat), y = colnames(cor_mat), type = "heatmap", colors = "Blues")
```

> (b) Sur la base de ces analyses, quelles variables vous semblent pertinentes pour l'ACP ? Quelles variables explicatives proposez-vous ?

```{r}
        #On ne garde que les variables pertinentes pour l'ACP
        sleep_pour_acp <- sleep %>%
                select(sleep_total, sleep_rem, awake, brain_wt, body_wt, brain_body_ratio, gest_day, name)

        #On vérifie qu'il n'y a pas de valeurs manquantes
        sum(is.na(sleep_pour_acp))

        #On vérifie qu'il n'y a pas de valeurs négatives
        sum(sleep_pour_acp < 0)



```

2. On propose de compléter les données manquantes de la colonne `sleep_rem` en utilisant une technique de regression  par _la méthode des moindres carrés_. Quelle valeur est estimée pour l'individu _Lamantin_ ? Compléter les valeurs manquantes.

```{r}
# On crée un nouveau jeu de données en ne gardant que les lignes où sleep_rem est renseigné
sleep_rem <- sleep %>%
        filter(!is.na(sleep_rem))

# On crée un modèle de régression linéaire entre sleep_rem et les autres variables
model <- lm(sleep_rem ~ sleep_total + awake + brain_wt + body_wt + brain_body_ratio + gest_day, data = sleep_rem)

# On prédit la valeur de sleep_rem pour le lamantin
predict(model, newdata = sleep[sleep$name == "Lamantin", -c(1, 2, 3, 4)])

# On complète les valeurs manquantes
sleep[sleep$name == "Lamantin", "sleep_rem"] <- predict(model, newdata = sleep[sleep$name == "Lamantin", -c(1, 2, 3, 4)])

```

3. Calculer les valeurs propres de la matrice des données `sleep`. Combien d'axes proposez vous de retenir pour l'ACP ? Détaillez votre réponse.

```{r}
# On supprime name
sleep_pour_acp <- sleep_pour_acp %>% select(-name)
# On utilise la fonction PCA de factoextra
pca <- PCA(sleep_pour_acp, graph = FALSE, ncp = 7)

# On affiche les valeurs propres
pca$eig

# On affiche le pourcentage d'inertie expliqué par chaque axe
pca$eig / sum(pca$eig)

# On affiche le biplot
fviz_pca_biplot(pca, repel = TRUE)

# On affiche le cercle des corrélations
fviz_pca_var(pca, col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# On affiche le tableau des corrélations
pca$var$coord
```


4. Analyse des variables

> (a) Commentez la qualité de représentation et la contribution de chaque variable quant aux axes retenus.
> > Les variables `sleep_total`, `awake` sont les plus représentatives. Les variables `sleep_rem`, `gest_day`, `brain_wt` et `body_wt` ont aussi une bonne contribution, cependant inferieure aux deux autres. La variable `brain_body_ratio` est la moins représentative.

> (b) Interpréter la signification des axes retenus. Vous pourrez vous aider de la contribution des variables aux axes factoriels.
> > Le temps d'eveil est positivement correle avec le temps de sommeil totale et REM. Le poid du cerveau est aussi correle avec le poid du corps.

5. Analyse des individus

> (a) Présenter la projection des individus dans l'espace factoriel retenu. Vous colorerez dans un premier temps les points en fonction de la variable explicative retenue.
```{r}
# On affiche le biplot avec les individus colorés en fonction de la variable explicative (avec pca ind)
fviz_pca_ind(pca, col.ind = "sleep_total", repel = TRUE)
```

> >  Pour une projection 3D, on utilisera la commande `plot_ly(df, x = ~Dim.1, y = ~Dim.2, z = ~Dim.3)` de la librairie `plotly` où `df` est votre dataframe des coordonnées des individus et `Dim.k`, la colonne des coordonnées sur l'axe $k$. 
```{r}
# On affiche le biplot avec les individus colorés en fonction de la variable explicative (avec plotly)
# On crée un dataframe avec les coordonnées des individus
df <- data.frame(pca$ind$coord)

# On ajoute le nom des individus
df$name <- sleep$name

# On affiche le biplot avec les individus colorés en fonction de la variable explicative (avec plotly)
plot_ly(df, x = ~Dim.1, y = ~Dim.2, z = ~Dim.3, color = ~name, type = "scatter3d", mode = "markers")
```

> (b) Colorer les individus en fonction de leur qualité de réprésentation aux axes factoriels puis en fonction de la contribution. Commentez ces résultats. 

```{r}
# On affiche le biplot avec les individus colorés en fonction de leur qualité de représentation aux axes factoriels
fviz_pca_ind(pca, col.ind = "contrib", repel = TRUE)
```

## Classiffication de caractères manuscrits

On considère le fichier `mnist.csv` sur Celene. Ces données proviennent de la base MNIST^[http://yann.lecun.com/exdb/mnist/] sur laquelle des milliers de chercheurs ont travaillé. Elle est constituée initialement de 70.000 chiffres manuscrits au format 28 pixels par 28 pixels où chaque pixel est représenté par un niveau de gris allant de 0 à 255. Un chiffre manuscrit est vu comme un vecteur de $\{0, ..., 255\}^{28\times28}$.


Pour limiter le temps de calcul et la mémoire nécessaire, nous ne considérons que les 20.000 premiers chiffres manuscrits de la base originale. On donne la description des colonnes suivantes:

- chaque ligne correspond à un chiffre manuscrit.

- la première colonne contient la _classe_ (ou label) du caractère, c'est-à-dire le chiffre qu'il représente.

- les colonnes suivantes, contiennent les valeurs des $28\times 28=784$ pixels de l'image en commençant par le coin supérieur gauche et parcourant l’image ligne par ligne.

On donne la fonction de visualisation suivante: 

```{r}
img <- function(data, row_index){

    r <- as.numeric(data[row_index, 2:785])
    im <- matrix(nrow = 28, ncol = 28)
    j <- 1
    for(i in 28:1){
        im[,i] <- r[j:(j+27)]
        j <- j+28
    }  
    png(file = "out.png", width = 210, height = 300)

    image(x = 1:28, 
          y = 1:28, 
          z = im, 
          col=gray((0:255)/255), 
          main = paste("Number:", data[row_index, 1]))
    dev.off()
}
```

L'appel `img(mnist, i)` retourne la figure correspondant au caractère manuscrit ligne $i$. 

1. Statistiques descriptives

> (a) Proposer une analyse préliminaire par statistiques descriptives du jeu de données `mnist`. Votre analyse devra contenir notamment:

> >- Nombre de caractères de chaque classe.

```{r}
# Definition du jeu de données mnist : label, pixel0, pixel1, ..., pixel783
        #Nombre de caractères de chaque classe dans un plotly avec de la couleur
        mnist %>%
                group_by(label) %>%
                summarise(n = n()) %>%
                plot_ly(x = ~label, y = ~n, type = "bar", text = ~n, textposition = "auto", color = ~label)
```

> >- Des premiers indicateurs sur la proportion de gris par pixel, puis agrégé par classe de caractère.

```{r}
        #Proportion de gris par pixel
        #Transformation de label comme valeur discrète
        mnist$label <- as.factor(mnist$label)
        #On calcule la moyenne de chaque pixel par label et on affiche le résultat avec des bar groupés par label avec des couleurs avec plotly
        mnist %>%
                group_by(label) %>%
                summarise_all(mean) %>%
                gather(key = "pixel", value = "proportion_gris", -label) %>%
                mutate(pixel = as.numeric(gsub("pixel", "", pixel))) %>%
                plot_ly(x = ~pixel, y = ~proportion_gris, color = ~label, type = "bar")
```

```{r}
        #On refait la meme chose mais avec ggplot
        mnist %>%
                group_by(label) %>%
                summarise_all(mean) %>%
                gather(key = "pixel", value = "proportion_gris", -label) %>%
                ggplot(aes(x = pixel, y = proportion_gris, group = label, color = label)) +
                geom_line() +
                theme_bw() +
                theme(legend.position = "bottom") +
                labs(x = "Pixel", y = "Proportion de gris", title = "Proportion de gris par pixel")
```

> (b) Sur la base de ces analyses, certaines zones de l'image vous semblent t-elles plus pertinentes pour l'analyse ? Lesquelles ? Pourquoi ?

> > On remarque que les pixels centraux sont plus importants que les autres. On peut donc se concentrer sur ces pixels pour l'analyse.

2. Classification par l'algorithme des $k$ plus proches voisins (kNN). 

> L'algorithme des $k$ proches voisins ($k$-Nearest Neightbors) est une méthode de prédiction qui, pour une base de données d'apprentissage, cherche à déterminer la classe d'une donnée inconnue. 

> L'idée générale de cet algorithme est très simple. Pour une nouvelle donnée d'entrée $x$, on évalue sa distance à toutes les autres données connues de notre base d'apprentissage $\mathbf{X}$. 

> On rappelle que la distance euclidienne entre deux éléments $x,y\in \mathbb{R}^p$ est définie telle que:

$$\left\Vert x-y\right\Vert = \sqrt{\sum_{i=1}^p (x_i-y_i)^2}$$

> On retient ensuite uniquement les $k$ voisins $\mathbf{X_i}$ les plus proches de $x$. On regarde alors les classes $\mathbf{Y_i}$ de ces données $\mathbf{X_i}$, puis on prédit la classe la plus présente. Par défaut on utilisera $k=1$.

> (a) En assumant que $\mathbf{X}$ est doté de $n$ individus définis dans un espace de dimension $p$. Quelle est la complexité de l'algorithme des $k$-Nearest Neightbors pour $k = 1$. 
> > La complexité de l'algorithme des $k$-Nearest Neightbors pour $k = 1$ est de $O(n)$.
> (b) Diviser le jeu de données `mnist` en deux ensembles : 

> > - Un ensemble d'apprentissage (train set) qui contiendra 80% du jeu initial.

> > - Un ensemble test (test set) qui contiendra le reste des données.

```{r}
# On crée un jeu de données train qui contient 80% des données de mnist et un jeu de données test qui contient les 20% restants
        train <- mnist %>%
                group_by(label) %>%
                sample_frac(0.8)
        test <- mnist %>%
                anti_join(train)
```

> On veillera à conserver les labels des deux ensembles dans un vecteur à part. 

> (c) La commande `knn` du package `class` permet de réaliser une classification à l'aide de l'algorithme des $k$-Nearest Neightbors:

> > Appliquer l'algorithme kNN (avec $k=1$) sur votre ensemble d'apprentissage et de test. On veillera à sauvegarder le résultat de la fonction dans une variable `prediction`:

> > > `prediction <- knn(...)`
```{r, eval = FALSE}
# On applique l'algorithme knn avec k=1 sur l'ensemble d'apprentissage et de test
start.time1 <- Sys.time()
        prediction <- knn(train[, -1], test[, -1], cl = train$label, k = 1)
kmeans_time1 <- Sys.time() - start.time1

# On affiche le temps d'execution de l'algorithme knn
kmeans_time1
```

> > Donner le temps d'exécution de l'algorithme.
> > > Le temps d'exécution de l'algorithme est de 12 minutes.

> (d) La commande `table(prediction, Y_test_label)` permet de dresser la _matrice de confusion_ $C$ de la classification effectuée. Le nombre $c_{ij}$ représente le nombre d'éléments de la classe $i$ classifiés en tant que $j$. 

> > Quel est le pourcentage de caractères manuscrits de l’ensemble de test qui ont été mal classés ? Cet algorithme vous semble t-il efficace ? Quel critique peut-on lui faire ?
```{r}
# On calcule le pourcentage de caractères manuscrits de l'ensemble de test qui ont été mal classés
        table(prediction, test$label)
        sum(diag(table(prediction, test$label)))/sum(table(prediction, test$label)) * 100
```

> (e) Pour chaque classe, identifier un exemple de caractère mal classé par l'algorithme. Vous illustrerez ces caractères à l'aide de la fonction `img` donnée plus haut et ferez figurer la classe prédite et réelle des caractères. 
```{r}
# On crée un jeu de données qui contient les caractères mal classés
        mal_classe <- test %>%
                mutate(prediction = prediction) %>%
                filter(label != prediction)
# Pour chaque mal classé on appel la fonction img(data, i) qui permet d'afficher le caractère i et copie out.png dans le dossier erreur avec pour nom le label et la prediction
        for (i in 1:nrow(mal_classe)) {
                img(mal_classe, i)
                file.rename("out.png", paste0("erreur/", mal_classe$label[i], "_", mal_classe$prediction[i], ".png"))
        }
# On fait un rapport avec un tableau sur le label et la prediction
#         knitr::kable(mal_classe[, c("label", "prediction")])
```

3. Prétraitement-compression des données par ACP

> (a) Effectuer une ACP du jeu `mnist` et analyser la série des valeurs propres. Combien de composantes doivent être conservées pour avoir plus de 95% de l’inertie.
```{r}
# On effectue une ACP du jeu mnist avec la fonction acp
        mnist_acp <- PCA(mnist[, -1], graph = FALSE)
```

```{r}
# On affiche la série des valeurs propres
         mnist_acp$eig
# On affiche la screeplot
fviz_screeplot(mnist_acp, ncp = 20)

# On affiche la courbe de l'inertie cumulée
fviz_eig(mnist_acp, addlabels = TRUE, ylim = c(0, 100))

# On affiche le pca ind avec les couleurs indiquant leurs importance du cos2
fviz_pca_ind(mnist_acp, col.var = "cos2", repel = TRUE, legend.title = "Cos2")
```


> > On conserve 95% de l'inertie avec 303 composantes.
>
> (b) Appliquer à nouveau l'algorithme kNN mais ici vous utiliserez comme jeu initial la projection via ACP réalisée à la question précédente. Que constatez-vous ? 
```{r}
# On realise ACP avec 303 composantes
        mnist_acp_303 <- PCA(mnist[, -1], graph = FALSE, ncp = 303)
# On applique l'algorithme knn avec k=1 sur l'ensemble d'apprentissage et de test
# On convertit les données en data.frame
    mnist_acp_303 <- as.data.frame(mnist_acp_303$ind)
    mnist_acp_303$label <- mnist$label
# On divise le jeu de données en deux ensembles : un ensemble d'apprentissage (train set) qui contiendra 80% du jeu initial et un ensemble test (test set) qui contiendra le reste des données.
    set.seed
    train <- mnist_acp_303[sample(1:nrow(mnist_acp_303), 0.8 * nrow(mnist_acp_303)), ]
    test <- mnist_acp_303 %>%
            anti_join(train)
# On applique l'algorithme knn avec k=1 sur l'ensemble d'apprentissage et de test
start.time2 <- Sys.time()
        prediction <- knn(train[, -1], test[, -1], cl = train$label, k = 1)
kmeans_time2 <- Sys.time() - start.time2
kmeans_time2
```


> (c) Dresser la nouvelle matrice de confusion à l'issu de la classification précédente. Comparer ces résultats avec la matrice de la question 2. (d). Que peut-on dire ?
```{r}
# On calcule le pourcentage de caractères manuscrits de l'ensemble de test qui ont été mal classés
        table(prediction, test$label)
        sum(diag(table(prediction, test$label)))/sum(table(prediction, test$label)) * 100
```

> > On constate que le pourcentage de caractères manuscrits de l'ensemble de test qui ont été mal classés est de 6% contre 4% sans ACP.
> > On constate donc que l'ACP n'améliore pas la classification.